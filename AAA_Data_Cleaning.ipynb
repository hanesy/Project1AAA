{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dependencies and Load Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CSV Files\n",
    "\n",
    "#Source: Sobhan Moosavi - \"US Accidents (2.25 million records) - A Countrywide Traffi Accident Dataset (2016-2019)\"\"\n",
    "# https://www.kaggle.com/sobhanmoosavi/us-accidents\n",
    "file = 'Resources/ignore/US_Accidents_May19.csv'\n",
    "df_accidents = pd.read_csv(file)\n",
    "\n",
    "#Source: US Department of Transportation - \"Highway Statistic 2017 - Licensed Drivers by State\"\n",
    "# https://www.fhwa.dot.gov/policyinformation/statistics/2017/\n",
    "dl_file = 'Resources/US_DLCount.csv'\n",
    "df_dl = pd.read_csv(dl_file, thousands=',')\n",
    "\n",
    "#Source: American Community Survey - \"Annual Estimates of the Resident Population...\"\"\n",
    "#https://www.census.gov/content/census/en/data/tables/time-series/demo/popest/2010s-state-total.html#par_textimage_1574439295\n",
    "statepop_file = 'Resources/US_State_Population.csv'\n",
    "df_statepop = pd.read_csv(statepop_file, encoding='iso-8859-1', thousands=',')\n",
    "\n",
    "#Source: American Community Survey - \"County Population Totals and Components of Change\"\n",
    "# https://www.census.gov/content/census/en/data/tables/time-series/demo/popest/2010s-counties-total.html#par_textimage_242301767\n",
    "countypop_file = 'Resources/US_County_Population.csv'\n",
    "df_countypop = pd.read_csv(countypop_file, encoding='iso-8859-1')\n",
    "\n",
    "#Source: American Community Survey - \"Annual Estimates of the Resident Population for Incorporated Places of 50,000 or More\"\n",
    "#https://www.census.gov/content/census/en/data/tables/time-series/demo/popest/2010s-total-cities-and-towns.html\n",
    "citypop_file = 'Resources/US_Cities_Population.csv'\n",
    "df_citypop = pd.read_csv(citypop_file, encoding='iso-8859-1')\n",
    "\n",
    "# Source: NOAA's (National Oceanic and Atmospheric Administration) National Centers for Environmental Information (NCEI)\n",
    "# https://www.ncdc.noaa.gov/cdo-web/\n",
    "weather_file = 'Resources/1998221.csv'\n",
    "weather_days_source = pd.read_csv(weather_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary utilized for the DFs\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL', \n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Palau': 'PW',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Accidents Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_accidents = df_accidents\n",
    "\n",
    "#Create columns for time\n",
    "df_clean_accidents[\"Start_Year\"] = df_clean_accidents[\"Start_Time\"].agg(lambda x: x.split(\"-\")[0])\n",
    "df_clean_accidents[\"Start_Month\"] = df_clean_accidents[\"Start_Time\"].agg(lambda x: x.split(\"-\")[1])\n",
    "df_clean_accidents[\"Start_Hr\"] = df_clean_accidents[\"Start_Time\"].agg(lambda x: x.split()[1])\n",
    "df_clean_accidents[\"Start_Hr\"] = df_clean_accidents[\"Start_Hr\"].agg(lambda x: x.split(\":\")[0])\n",
    "\n",
    "#Remove 2015 and 2019 \n",
    "df_clean_accidents = df_clean_accidents[df_clean_accidents[\"Start_Year\"] != \"2019\"]\n",
    "df_clean_accidents = df_clean_accidents[df_clean_accidents[\"Start_Year\"] != \"2015\"]\n",
    "\n",
    "df_clean_accidents.to_csv(\"Clean_Data/ignore/accidents.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Licensed Drivers Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DL by State\n",
    "df_clean_dl = df_dl.replace({\"Alaska 2/\": \"Alaska\",\n",
    "                                       \"Hawaii 2/\": \"Hawaii\",\n",
    "                                       \"Dist. of Col.\": \"District of Columbia\"})\n",
    "state_list = df_clean_dl[\"STATE\"].str.strip()\n",
    "df_clean_dl[\"STATE\"] = state_list\n",
    "df_clean_dl = df_clean_dl.replace({\"STATE\": us_state_abbrev})\n",
    "df_clean_dl.rename(columns={'STATE': 'State'}, inplace=True)\n",
    "df_clean_dl.to_csv(\"Clean_Data/licensed_drivers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Population Data</h1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>State</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_statepop = df_statepop\n",
    "df_clean_statepop['Geographic Area'] = df_clean_statepop['Geographic Area'].str.replace(\".\", \"\")\n",
    "pop_state_list = df_clean_statepop[\"Geographic Area\"].str.strip()\n",
    "df_clean_statepop[\"Geographic Area\"] = pop_state_list\n",
    "df_clean_statepop = df_clean_statepop.replace({\"Geographic Area\": us_state_abbrev})\n",
    "df_clean_statepop.to_csv(\"Clean_Data/population_state.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>County</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_countypop = df_countypop\n",
    "df_clean_countypop.columns = [x.strip().replace('Population Estimate (as of July 1) - ', '') for x in df_clean_countypop.columns]\n",
    "df_clean_countypop.columns = [x.strip().replace('April 1, ', '') for x in df_clean_countypop.columns]\n",
    "df_clean_countypop.columns = [x.strip().replace('Census', '') for x in df_clean_countypop.columns]\n",
    "df_clean_countypop.columns = [x.strip().replace('-', '') for x in df_clean_countypop.columns]\n",
    "df_clean_countypop.columns = [x.strip().replace('Estimates Base', '') for x in df_clean_countypop.columns]\n",
    "\n",
    "df_clean_countypop[\"County\"] = df_clean_countypop[\"Geography\"].agg(lambda x: x.split(\",\")[0])\n",
    "df_clean_countypop[\"State\"] = df_clean_countypop[\"Geography\"].agg(lambda x: x.split(\",\")[1])\n",
    "\n",
    "state_list = df_clean_countypop[\"State\"].str.strip()\n",
    "df_clean_countypop[\"State\"] = state_list\n",
    "df_clean_countypop = df_clean_countypop.replace({\"State\": us_state_abbrev})\n",
    "df_clean_countypop['County'] = df_clean_countypop['County'].str.replace(\" County\", \"\")\n",
    "\n",
    "df_clean_countypop.to_csv(\"Clean_Data/population_county.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>City</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_citypop = df_citypop\n",
    "df_clean_citypop.columns = [x.strip().replace('Population Estimate (as of July 1) - ', '') for x in df_clean_citypop.columns]\n",
    "df_clean_citypop.columns = [x.strip().replace('April 1, ', '') for x in df_clean_citypop.columns]\n",
    "df_clean_citypop.columns = [x.strip().replace('Census', '') for x in df_clean_citypop.columns]\n",
    "df_clean_citypop.columns = [x.strip().replace('-', '') for x in df_clean_citypop.columns]\n",
    "df_clean_citypop.columns = [x.strip().replace('Estimates Base', '') for x in df_clean_citypop.columns]\n",
    "\n",
    "df_clean_citypop[\"City\"] = df_clean_citypop[\"Geography.2\"].agg(lambda x: x.split(\",\")[0])\n",
    "df_clean_citypop[\"State\"] = df_clean_citypop[\"Geography.2\"].agg(lambda x: x.split(\",\")[1])\n",
    "\n",
    "state_list = df_clean_citypop[\"State\"].str.strip()\n",
    "df_clean_citypop[\"State\"] = state_list\n",
    "df_clean_citypop = df_clean_citypop.replace({\"State\": us_state_abbrev})\n",
    "df_clean_citypop['City'] = df_clean_citypop['City'].str.replace(\" city\", \"\")\n",
    "\n",
    "df_clean_citypop.to_csv(\"Clean_Data/population_city.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Weather Type per State Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Data for Weather Type per State\n",
    "\n",
    "# 01 - Create relevant df with data for the weather comparison\n",
    "df_weather = df_clean_accidents[['ID', 'Severity', 'Start_Time', 'City', 'County', 'State', 'Timezone',\n",
    "                 'Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)',\n",
    "                 'Wind_Direction', 'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition',\n",
    "                 'Sunrise_Sunset', 'Start_Year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Data for Weather Type per State\n",
    "\n",
    "# 02 - Delete rows with Weather_Condition as null\n",
    "df_weather = df_weather.dropna(subset=['Weather_Condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Data for Weather Type per State\n",
    "\n",
    "# 03 - Create smaller clusters of Weather Type\n",
    "df_weather['Weather_Condition_Corrected'] = df_weather['Weather_Condition']\n",
    "df_weather['Weather_Condition_Corrected'] = df_weather['Weather_Condition_Corrected'].replace(\n",
    "    {\"Mostly Cloudy\": \"Cloudy\",\n",
    "     \"Partly Cloudy\": \"Cloudy\",\n",
    "     \"Scattered Clouds\": \"Cloudy\",\n",
    "     \"Funnel Cloud\": \"Cloudy\",\n",
    "     'Overcast': 'Cloudy',\n",
    "     'Drizzle': 'Rain',\n",
    "     'Light Drizzle': 'Rain',\n",
    "     'Light Freezing Drizzle': 'Rain',\n",
    "     'Heavy Drizzle': 'Rain',\n",
    "     'Heavy Freezing Drizzle': 'Rain',\n",
    "     'Widespread Dust': 'Dust',\n",
    "     'Dust Whirls': 'Dust',\n",
    "     'Volcanic Ash': 'Dust',\n",
    "     'Sand': 'Dust',\n",
    "     'Blowing Sand': 'Dust',\n",
    "     'Haze': 'Fog',\n",
    "     'Patches of Fog': 'Fog',\n",
    "     'Light Freezing Fog': 'Fog',\n",
    "     'Shallow Fog': 'Fog',\n",
    "     'Light Fog': 'Fog',\n",
    "     'Mist': 'Fog',\n",
    "     'Small Hail': 'Hail',\n",
    "     'Light Hail': 'Hail',\n",
    "     'Ice Pellets': 'Hail',\n",
    "     'Light Haze': 'Fog',\n",
    "     'Light Ice Pellets': 'Hail',\n",
    "     'Heavy Ice Pellets': 'Hail',\n",
    "     'Light Rain': 'Rain',\n",
    "     'Heavy Rain': 'Rain',\n",
    "     'Light Thunderstorms and Rain': 'Thunderstorm',\n",
    "     'Heavy Thunderstorms and Rain': 'Thunderstorm',\n",
    "     'Thunderstorms and Rain': 'Thunderstorm',\n",
    "     'Light Freezing Rain': 'Rain',\n",
    "     'Light Rain Showers': 'Rain',\n",
    "     'Rain Showers': 'Rain',\n",
    "     'Heavy Rain Showers': 'Rain',\n",
    "     'Snow Grains': 'Snow',\n",
    "     'Light Snow Grains': 'Snow',\n",
    "     'Heavy Freezing Rain': 'Rain',\n",
    "     'Heavy Smoke': 'Smoke',\n",
    "     'Light Snow': 'Snow',\n",
    "     'Heavy Snow': 'Snow',\n",
    "     'Blowing Snow': 'Snow',\n",
    "     'Light Snow Showers': 'Snow',\n",
    "     'Light Thunderstorms and Snow': 'Snow',\n",
    "     'Low Drifting Snow': 'Snow',\n",
    "     'Heavy Thunderstorms and Snow': 'Snow',\n",
    "     'Thunderstorms and Snow': 'Snow',\n",
    "     'Heavy Blowing Snow': 'Snow',\n",
    "     'Light Blowing Snow': 'Snow',\n",
    "     'Snow Showers': 'Snow',\n",
    "     'Heavy Thunderstorms with Small Hail': 'Thunderstorm',\n",
    "     'Light Thunderstorm': 'Thunderstorm'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Data for Weather Type per State\n",
    "\n",
    "# 04 - Export Cleaned Weather type and State to csv\n",
    "\n",
    "df_weather.to_csv(\"Clean_Data/ignore/df_weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Weather Days for DEN, SFO and RI Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Weather Days_source\n",
    "\n",
    "# 01 - extracting the needed columns\n",
    "weather_days_dv_ri_sf = weather_days_source[['NAME', 'DATE', 'PRCP', 'SNOW', 'WT01', 'WT02', \n",
    "                                               'WT03', 'WT04', 'WT05', 'WT06', 'WT07', 'WT08', 'WT09']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Weather Days_source\n",
    "\n",
    "# 02 - creating Year column\n",
    "weather_days_dv_ri_sf[\"YEAR\"] = weather_days_dv_ri_sf[\"DATE\"].agg(lambda x: x.split(\"-\")[0])\n",
    "\n",
    "# 03 - creating columns to access which type of weather do we have\n",
    "weather_days_dv_ri_sf['PRCP_calc'] = ''\n",
    "weather_days_dv_ri_sf['SNOW_calc'] = ''\n",
    "weather_days_dv_ri_sf['Weather_cond'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Weather Days_source\n",
    "\n",
    "# 04 - Label Snowy and Rainy days\n",
    "for i in range(0,len(weather_days_dv_ri_sf)):\n",
    "\n",
    "    if weather_days_dv_ri_sf.iloc[i,2] > 0.0:\n",
    "        weather_days_dv_ri_sf.iloc[i,14] = 'y'\n",
    "    else: \n",
    "        weather_days_dv_ri_sf.iloc[i,14] = 'n'\n",
    "        \n",
    "    if weather_days_dv_ri_sf.iloc[i,3] > 0.0:\n",
    "        weather_days_dv_ri_sf.iloc[i,15] = 'y'\n",
    "    else: \n",
    "        weather_days_dv_ri_sf.iloc[i,15] = 'n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Weather Days_source\n",
    "\n",
    "# 05 - Final labeling of different weather types\n",
    "\n",
    "for i in range(0,len(weather_days_dv_ri_sf)):\n",
    "\n",
    "# Code -> Official Description for Weather Type -> Our Weather Type\n",
    "# WT01 -> Fog, ice fog, or freezing fog (may include heavy fog) -> Fog\n",
    "# WT02 -> Heavy fog or heaving freezing fog (not always distinguished from fog) -> Fog\n",
    "# WT03 -> Thunder -> Thunder\n",
    "# WT04 -> Ice pellets, sleet, snow pellets, or small hail -> Hail\n",
    "# WT05 -> Hail (may include small hail) -> Hail\n",
    "# WT06 -> Glaze or rime -> Snow\n",
    "# WT07 -> Dust, volcanic ash, blowing dust, blowing sand, or blowing obstruction -> Dust\n",
    "# WT08 -> Smoke or haze -> Smoke\n",
    "# WT09 -> Blowing or drifting snow -> Snow\n",
    "\n",
    "    \n",
    "# Based on the existance of snow (WT06 and WT09 and SNOW = Snow)\n",
    "    if (weather_days_dv_ri_sf.iloc[i,9] > 0 or weather_days_dv_ri_sf.iloc[i,12] > 0 or weather_days_dv_ri_sf.iloc[i,15] == 'y'):\n",
    "        weather_days_dv_ri_sf.iloc[i,16] = 'Snow'\n",
    "\n",
    "# Based on the existance of thunderstorm (WT03 = Thunder)\n",
    "    elif weather_days_dv_ri_sf.iloc[i,6] > 0:\n",
    "        weather_days_dv_ri_sf.iloc[i,16] = 'Thunderstorm'\n",
    "\n",
    "# Based on the existance of rain (PRCP = Rain)\n",
    "    elif weather_days_dv_ri_sf.iloc[i,14] == 'y':\n",
    "        weather_days_dv_ri_sf.iloc[i,16] = 'Rain'\n",
    "\n",
    "# Based on the existance of hail (WT04 and WT05 = Hail)\n",
    "    elif (weather_days_dv_ri_sf.iloc[i,7] > 0 or weather_days_dv_ri_sf.iloc[i,8] > 0):\n",
    "        weather_days_dv_ri_sf.iloc[i,16] = 'Hail'\n",
    "\n",
    "# Based on the existance of fog (WT01 and WT02 = Fog)\n",
    "    elif (weather_days_dv_ri_sf.iloc[i,4] > 0 or weather_days_dv_ri_sf.iloc[i,5] > 0):\n",
    "        weather_days_dv_ri_sf.iloc[i,16] = 'Fog'\n",
    "\n",
    "# Based on the existance of fog (WT07 = Dust)\n",
    "    elif weather_days_dv_ri_sf.iloc[i,10] > 0:\n",
    "        weather_days_dv_ri_sf.iloc[i,16] = 'Dust'\n",
    "\n",
    "# Based on the existance of fog (WT08 = Smoke)\n",
    "    elif weather_days_dv_ri_sf.iloc[i,11] > 0:\n",
    "        weather_days_dv_ri_sf.iloc[i,16] = 'Smoke'\n",
    "    \n",
    "# All the remaining should be Clear/Cloudy\n",
    "    else:\n",
    "        weather_days_dv_ri_sf.iloc[i,16] = 'Clear/Cloudy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning Weather Days_source\n",
    "\n",
    "# 06 - Export Cleaned Weather days to csv\n",
    "\n",
    "weather_days_dv_ri_sf.to_csv(\"Clean_Data/weather_days_dv_ri_sf.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
