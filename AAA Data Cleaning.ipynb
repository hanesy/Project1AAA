{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Dependencies and Load Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load CSV Files\n",
    "\n",
    "#Source: Sobhan Moosavi - \"US Accidents (2.25 million records) - A Countrywide Traffi Accident Dataset (2016-2019)\"\"\n",
    "# https://www.kaggle.com/sobhanmoosavi/us-accidents\n",
    "file = 'Resources/ignore/US_Accidents_May19.csv'\n",
    "df_accidents = pd.read_csv(file)\n",
    "\n",
    "#Source: US Department of Transportation - \"Highway Statistic 2017 - Licensed Drivers by State\"\n",
    "# https://www.fhwa.dot.gov/policyinformation/statistics/2017/\n",
    "dl_file = 'Resources/US_DLCount.csv'\n",
    "df_dl = pd.read_csv(dl_file, thousands=',')\n",
    "\n",
    "#Source: American Community Survey - \"Annual Estimates of the Resident Population...\"\"\n",
    "#https://www.census.gov/content/census/en/data/tables/time-series/demo/popest/2010s-state-total.html#par_textimage_1574439295\n",
    "statepop_file = 'Resources/US_State_Population.csv'\n",
    "df_statepop = pd.read_csv(statepop_file, encoding='iso-8859-1', thousands=',')\n",
    "\n",
    "#Source: American Community Survey - \"County Population Totals and Components of Change\"\n",
    "# https://www.census.gov/content/census/en/data/tables/time-series/demo/popest/2010s-counties-total.html#par_textimage_242301767\n",
    "\n",
    "countypop_file = 'Resources/US_County_Population.csv'\n",
    "df_countypop = pd.read_csv(countypop_file, encoding='iso-8859-1')\n",
    "\n",
    "#Source: Amerian Community Survey - \"Annual Estimates of the Resident Population for Incorporated Places of 50,000 or More\"\n",
    "#https://www.census.gov/content/census/en/data/tables/time-series/demo/popest/2010s-total-cities-and-towns.html\n",
    "citypop_file = 'Resources/US_Cities_Population.csv'\n",
    "df_citypop = pd.read_csv(citypop_file, encoding='iso-8859-1')\n",
    "\n",
    "###Diana needs to review and share csv###\n",
    "# #Source:\n",
    "# file1 = 'Resources/TMC_decoding.csv'\n",
    "# TMC_decoding = pd.read_csv(file1)\n",
    "\n",
    "# #Source:\n",
    "# file2 = 'Resources/denver_weather_num_days.csv'\n",
    "# denver_weather_days = pd.read_csv(file2)\n",
    "# denver_weather_days.set_index('weather_denver', inplace = True)\n",
    "\n",
    "# #Source:\n",
    "# file3 = 'Resources/rhode_island_weather_num_days_calc.csv'\n",
    "# ri_weather_days = pd.read_csv(file3)\n",
    "# ri_weather_days.set_index('weather_ri', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary utilized for the DFs\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL', \n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Palau': 'PW',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Accidents Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_accidents = df_accidents\n",
    "\n",
    "#Create columns for time\n",
    "df_clean_accidents[\"Start_Year\"] = df_clean_accidents[\"Start_Time\"].agg(lambda x: x.split(\"-\")[0])\n",
    "df_clean_accidents[\"Start_Month\"] = df_clean_accidents[\"Start_Time\"].agg(lambda x: x.split(\"-\")[1])\n",
    "df_clean_accidents[\"Start_Hr\"] = df_clean_accidents[\"Start_Time\"].agg(lambda x: x.split()[1])\n",
    "df_clean_accidents[\"Start_Hr\"] = df_clean_accidents[\"Start_Hr\"].agg(lambda x: x.split(\":\")[0])\n",
    "\n",
    "#Remove 2015 and 2019 \n",
    "df_clean_accidents = df_clean_accidents[df_clean_accidents[\"Start_Year\"] != \"2019\"]\n",
    "df_clean_accidents = df_clean_accidents[df_clean_accidents[\"Start_Year\"] != \"2015\"]\n",
    "\n",
    "df_clean_accidents.to_csv(\"Clean_Data/ignore/accidents.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Licensed Drivers Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DL by State\n",
    "df_clean_dl = df_dl.replace({\"Alaska 2/\": \"Alaska\",\n",
    "                                       \"Hawaii 2/\": \"Hawaii\",\n",
    "                                       \"Dist. of Col.\": \"District of Columbia\"})\n",
    "state_list = df_clean_dl[\"STATE\"].str.strip()\n",
    "df_clean_dl[\"STATE\"] = state_list\n",
    "df_clean_dl = df_clean_dl.replace({\"STATE\": us_state_abbrev})\n",
    "df_clean_dl.rename(columns={'STATE': 'State'}, inplace=True)\n",
    "df_clean_dl.to_csv(\"Clean_Data/licensed_drivers.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Population Data</h1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>State</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_statepop = df_statepop\n",
    "df_clean_statepop['Geographic Area'] = df_clean_statepop['Geographic Area'].str.replace(\".\", \"\")\n",
    "pop_state_list = df_clean_statepop[\"Geographic Area\"].str.strip()\n",
    "df_clean_statepop[\"Geographic Area\"] = pop_state_list\n",
    "df_clean_statepop = df_clean_statepop.replace({\"Geographic Area\": us_state_abbrev})\n",
    "df_clean_statepop.to_csv(\"Clean_Data/population_state.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>County</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_countypop = df_countypop\n",
    "df_clean_countypop.columns = [x.strip().replace('Population Estimate (as of July 1) - ', '') for x in df_clean_countypop.columns]\n",
    "df_clean_countypop.columns = [x.strip().replace('April 1, ', '') for x in df_clean_countypop.columns]\n",
    "df_clean_countypop.columns = [x.strip().replace('Census', '') for x in df_clean_countypop.columns]\n",
    "df_clean_countypop.columns = [x.strip().replace('-', '') for x in df_clean_countypop.columns]\n",
    "df_clean_countypop.columns = [x.strip().replace('Estimates Base', '') for x in df_clean_countypop.columns]\n",
    "\n",
    "df_clean_countypop[\"County\"] = df_clean_countypop[\"Geography\"].agg(lambda x: x.split(\",\")[0])\n",
    "df_clean_countypop[\"State\"] = df_clean_countypop[\"Geography\"].agg(lambda x: x.split(\",\")[1])\n",
    "\n",
    "state_list = df_clean_countypop[\"State\"].str.strip()\n",
    "df_clean_countypop[\"State\"] = state_list\n",
    "df_clean_countypop = df_clean_countypop.replace({\"State\": us_state_abbrev})\n",
    "df_clean_countypop['County'] = df_clean_countypop['County'].str.replace(\" County\", \"\")\n",
    "\n",
    "df_clean_countypop.to_csv(\"Clean_Data/population_county.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>City</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_citypop = df_citypop\n",
    "df_clean_citypop.columns = [x.strip().replace('Population Estimate (as of July 1) - ', '') for x in df_clean_citypop.columns]\n",
    "df_clean_citypop.columns = [x.strip().replace('April 1, ', '') for x in df_clean_citypop.columns]\n",
    "df_clean_citypop.columns = [x.strip().replace('Census', '') for x in df_clean_citypop.columns]\n",
    "df_clean_citypop.columns = [x.strip().replace('-', '') for x in df_clean_citypop.columns]\n",
    "df_clean_citypop.columns = [x.strip().replace('Estimates Base', '') for x in df_clean_citypop.columns]\n",
    "\n",
    "df_clean_citypop[\"City\"] = df_clean_citypop[\"Geography.2\"].agg(lambda x: x.split(\",\")[0])\n",
    "df_clean_citypop[\"State\"] = df_clean_citypop[\"Geography.2\"].agg(lambda x: x.split(\",\")[1])\n",
    "\n",
    "state_list = df_clean_citypop[\"State\"].str.strip()\n",
    "df_clean_citypop[\"State\"] = state_list\n",
    "df_clean_citypop = df_clean_citypop.replace({\"State\": us_state_abbrev})\n",
    "df_clean_citypop['City'] = df_clean_citypop['City'].str.replace(\" city\", \"\")\n",
    "\n",
    "df_clean_citypop.to_csv(\"Clean_Data/population_city.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TMC Decoding Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Diana needs to review###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Denver Weather Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Diana needs to review###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Rhode Island Weather Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Diana needs to review###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
